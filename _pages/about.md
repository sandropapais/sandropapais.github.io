---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info:

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---
Hello! I’m Sandro Papais, a Ph.D. Candidate at the [University of Toronto Robotics and Artificial Intelligence Laboratory (UTIAS)](https://www.trailab.utias.utoronto.ca/), supervised by [Prof. Steven Waslander](https://www.trailab.utias.utoronto.ca/steven-waslander/). I’m also an Affiliate Researcher at the [Vector Institute](https://vectorinstitute.ai/) and a Machine Learning Perception Researcher at [Zoox](https://zoox.com/), where I work on advancing perception systems for autonomous driving.  

Before my Ph.D., I developed visual navigation and autonomy software for interplanetary spacecraft at [NASA JPL, Mobility and Robotics Group](https://www-robotics.jpl.nasa.gov/), lunar landers and eVTOLs at [NGC Aerospace](https://ngcaerospace.com/en/), and rovers at European Space Agency, Research and Technology Centre (ESTEC).

My research lies at the intersection of 3D computer vision, machine learning, robotic perception, and motion forecasting, with a focus on **spatiotemporal world models** and **end-to-end autonomous driving models** that enable robots to perceive and act safely in dynamic environments.

Recently, I’ve been developing **camera and lidar-based temporal perception systems** that improve temporal reasoning in autonomous vehicles, allowing them to maintain object awareness through occlusions and reason about motion and object permanence. I’m the first author of **ForeSight (ICCV 2025)**, a multi-view streaming transformer for joint 3D detection and forecasting, and **SWTrack (ICRA 2024)**, a multiple-hypothesis tracking framework for autonomous driving. These works aim to bridge the gap between static perception and dynamic reasoning in robotic systems.  

My work has been recognized with the [Qualcomm Innovation Fellowship](https://www.qualcomm.com/research/university-relations/innovation-fellowship/2025-north-america) (2025), the Ontario Graduate Scholarship (2024), and [first place at the AutoDrive Challenge II](https://robotics.utoronto.ca/news/u-of-ts-self-driving-car-team-places-first-at-2024-autodrive-challenge-ii/) (2022) with the University of Toronto’s aUToronto team, [first place at the Spaceport America Genesis Cup](https://www.mcgill.ca/engineering/article/mcgill-rocket-team-soars-first-place-spaceport-america-cup) (2018). My past research has published in top robotics and computer vision venues, including a forthcoming book on motion forecasting for robotics, and was featured by [U of T Engineering News](https://robotics.utoronto.ca/news/u-of-t-engineering-researchers-are-making-self-driving-cars-safer-by-enhancing-tracking-abilities/) for advancing tracking in self-driving cars.

I’m always open to discussing research, collaborations, or new ideas — feel free to reach out!






